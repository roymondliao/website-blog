title: "Transformer Part 3"
date: 2019-12-16
lastmod: 2020-02-28
draft: true
authors: ["Roymond Liao"]
categories:
    - NLP
    - Deep Learning
tags: ["Self-attention", "Transformer"]
markup: mmark
image:
  placement: 2
  caption: "Photo by Christian Wagner on Unsplash"
  focal_point: "Center"
  preview_only: false


  # Reference

1. [The IIIustrated Transformer](https://jalammar.github.io/illustrated-transformer/)
2. [w淺談神經機器翻譯 & 用 Transformer 與 Tensorflow2](https://leemeng.tw/neural-machine-translation-with-transformer-and-tensorflow2.html#top)
3. [Attention is all you need 解讀](https://zhuanlan.zhihu.com/p/34781297)
4. [Transformer model for language understanding by google](https://www.tensorflow.org/tutorials/text/transformer)
5. [How Self-Attention with Relative Position Representations works](https://medium.com/@_init_/how-self-attention-with-relative-position-representations-works-28173b8c245a)
